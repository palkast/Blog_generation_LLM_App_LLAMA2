# Blog_generation_LLM_App_LLAMA2
This project is about end to end implementation of LLM model LLAMA2 developed by Meta from Hugging Face API using langchain and deployed on Stream Lit App.<br />

Llama2 - Meta is open source llm model.<br />

Steps:<br />

1.Download LLAMA2 model from Hugging face which is less parametrized model : https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML<br />
2.Create environments (venv)<br />
3.Create requirements.txt file<br /> 
4.Create app.py (application program to call the model and get response and deploy on StreamLit app)<br />
  a)Function To get response from LLAma 2 model<br />  
  b)Initialize LLama2 model<br />  
  c)Create Prompt Template<br />  
  d)Generate the response from the LLama 2 model<br />
  e)Now set the page for StreamLit app front end<br /> 
  f)Create header and input area for the front end<br />
  g)Get response from llama2 model using  input parameters : input text , no_words,blog_style<br />

